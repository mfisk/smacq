.\" $Header: /aolnet/dev/src/CVS/sgml/docbook-to-man/cmd/docbook-to-man.sh,v 1.1.1.1 1998/11/13 21:31:59 db3l Exp $
.\"
.\"	transcript compatibility for postscript use.
.\"
.\"	synopsis:  .P! <file.ps>
.\"
.de P!
.fl
\!!1 setgray
.fl
\\&.\"
.fl
\!!0 setgray
.fl			\" force out current output buffer
\!!save /psv exch def currentpoint translate 0 0 moveto
\!!/showpage{}def
.fl			\" prolog
.sy sed \-e 's/^/!/' \\$1\" bring in postscript file
\!!psv restore
.
.de pF
.ie     \\*(f1 .ds f1 \\n(.f
.el .ie \\*(f2 .ds f2 \\n(.f
.el .ie \\*(f3 .ds f3 \\n(.f
.el .ie \\*(f4 .ds f4 \\n(.f
.el .tm ? font overflow
.ft \\$1
..
.de fP
.ie     !\\*(f4 \{\
.	ft \\*(f4
.	ds f4\"
'	br \}
.el .ie !\\*(f3 \{\
.	ft \\*(f3
.	ds f3\"
'	br \}
.el .ie !\\*(f2 \{\
.	ft \\*(f2
.	ds f2\"
'	br \}
.el .ie !\\*(f1 \{\
.	ft \\*(f1
.	ds f1\"
'	br \}
.el .tm ? font underflow
..
.ds f1\"
.ds f2\"
.ds f3\"
.ds f4\"
'\" t 
.ta 8n 16n 24n 32n 40n 48n 56n 64n 72n  
.TH "smacq" "1" 
.SH "NAME" 
smacq \(em System for Modular Analysis and Continuous Queries 
.SH "DESCRIPTION" 
.PP 
The System for Modular Analysis and Continuous Queries (SMACQ) 
is an extensible component system for analyzing streams of 
structured data.  Users with a familiarity of SQL will 
immediately be comfortable using the basic features of the 
system.  However, there are additional object-relational and 
extensibility features that are described below.  This manpage 
describes the query syntax and the modules included with the 
system by default, which are grouped into sections for I/O, 
Boolean, Annotation, and Miscellaneous Analysis functions. 
Queries are executed using SMACQ's command-line utility, 
\fBsmacqq(1)\fR, or the SMACQ C++ API. 
 
.PP 
The primary difference from standard relational databases is 
that data is not stored in preloaded tables, but is instead 
produced by data source modules.  Also, the select operation 
does not automatically print fields.  If printable output is 
desired, use the \fBprint\fR command. 
 
.PP 
The following example prints the "srcip" and "dstip" fields from 
a stream of packets stored in a tcpdump-format file named "/tmp/dump": 
 
\f(CW	smacqq 'print srcip, dstip from pcapfile("/tmp/dump")' 
\fP  
Nested queries are also supported.  For example: 
 
\f(CW	print srcip, dstip from (uniq srcip, dstip from pcapfile("/tmp/dump")) 
\fP        
"Where" clauses are supported for both boolean tests based on <, 
<=, >, >=, =, !=, or arbitrary filtering functions. 
 
\f(CW	print dstip from pcapfile("/tmp/dump") where srcip = 128.129.1.2 
\fP  
\f(CW	print dstip from pcapfile("/tmp/dump") where mask(srcip, 128.129.0.0/16) 
\fP  
Aliasing with "as" is supported: 
 
\f(CW	print dstip, totalbytes from (select dstip, sum(len) as totalbytes from pcapfile("/tmp/dump")) 
\fP  
Joins are supported as well: 
 
\f(CW	print a.srcip, b.srcip from pcapfile("/tmp/dump") a, b where a.srcip != b.srcip	 
\fP  
When used with streams, joins require very large amounts of memory.  The "until"  
term can be used to define when elements can be removed from the pool of possible 
values in a join: 
 
\f(CW	print a.srcip, b.srcip from pcapfile("/tmp/dump") a until (new.a.ts > a.ts), b where a.srcip != b.srcip	 
\fP  
Extended relational algebra provides aggregate functions and the 
"group by" and "having" terms.  This syntax is supported, but with slightly 
different semantics.  For example, the following query would 
behave as it would in SQL: 
 
\f(CW	print dstip, sum(len) from pcapfile("/tmp/dump") group 
by dstip 
\fP  
but is also the same as: 
 
\f(CW	print dstip, sum from (groupby dstip, '--', sum, len from 
pcapfile("/tmp/dump")) 
\fP  
However the use of a function (such as "sum()") as one of the 
arguments will result in the "sum" module processing the data 
before the "print" module.  A module called in this way is 
expected to annotate the data object with a field of the same 
name as the function.  Thus, the sum field will be part of the 
object from now on.  Thus, it can also be used in subsequent 
arguments.  In addition, however, the module can cause other 
side-effects to the data.  Finally, functions can be used whether or 
not "group by" is used. 
 
 
.PP 
When queries are nested deeply, the syntax described above can become 
complex.  As a result, commas are optional between arguments, and SMACQ  
also supports the | symbol used in Unix shells.  The result is a syntax  
much more familiar to Unix shell users.  Thus the following queries are  
all equivalent: 
 
\f(CW	print srcip, dstip from (uniq srcip, dstip from pcapfile("/tmp/dump")) 
\fP  
\f(CW	print srcip, dstip from uniq srcip, dstip from pcapfile "/tmp/dump" 
\fP  
\f(CW	print srcip dstip from uniq srcip dstip from pcapfile "/tmp/dump" 
\fP  
\f(CW	pcapfile "/tmp/dump" | uniq srcip dstip | print srcip dstip 
\fP  
. 
 
.PP 
SMACQ is an extensible system that the user can add modules to. 
See the \fBsmacqp\fR(1) manpage for a detailed 
description of modules.  Many modules take flags which, like all 
arguments, can be separated with commas or spaces: 
 
\f(CW	print -v, srcip, dstip from pcapfile("/tmp/dump") 
\fP\  
 
.SH "INPUT/OUTPUT FUNCTIONS" 
.SS "Print" 
.PP 
\fBprint\fR [-x]  [-v]  [-B]  [-d \fIdelimiter\fR] fields \&...  
.PP 
Print the specified fields for every record that has them If 
the \fB\-v\fP option is given, then warnings are 
printed when fields aren't present, and field values are 
preceded by the field name.  If \fB\-x\fP option 
is given, fields are surrounded with XML-style tags.  
If the \fB\-B\fP option 
is specified, then output is not buffered (output is flushed 
after each record).  Fields are separated by a delimiter 
string which can be specified by \fB\-d\fP and 
defaults to TAB. 
 
.SS "Tabular Input" 
.PP 
\fBtabularinput\fR [-d \fIdelimiter\fR]  [-f \fIfilename\fR]  [field [:type]  \&...]  
.PP 
Read records from STDIN by default, or a filename specified with 
the \fB\-f\fP option, one per line, with fields delimited 
by TAB or an alterate delimiter specified by 
\fB\-d\fP.  If field names are specified, data 
columns are assigned those names sequentially.  If no field 
names are specified, or there are more columns that field 
names, unnamed fields are named numericaly starting at 1.  
 
.PP 
Field types can be specified by appending a colon and the type name to the end of the field name. 
If no type is sepecified for a field, it is treated as a double if possible, or a string otherwise. 
 
.SS "Packet Capture" 
.PP 
\fBpcaplive\fR [-i \fIinterface\fR]  [-s \fIsnaplen\fR]  [-p]  [\fIfilter\fR \&...]  
.PP 
The \fBpcaplive\fR module reads packets from a 
network interfaces using libpcap.  It can only be used at the 
beginning of a pipeline.  Root privileges are typically 
required to run this module. 
 
.PP 
The \fB\-i\fP option specifies an interface to 
listen on (default is \fBany\fP).  The 
\fB\-s\fP option specifies the maximum number of 
bytes per packet to capture (default is 68).  The 
\fB\-p\fP specifies that the interface should NOT be 
placed in promiscuous mode. 
 
.PP 
An optional filter string is a BPF filter string (see 
\fBtcpdump\fR(1)). 
 
.SS "Packet Trace File" 
.PP 
\fBpcapfile\fR \fIfilename\fR \&...  
.PP 
\fBpcapfile\fR -w \fIfilename\fR  [-l ]  [-s \fImegabytes\fR]  
.PP 
The \fBpcapfile\fR module either reads from or 
writes to a tcpdump-style, libpcap packet trace file.  If the 
module is at the beginning of a pipeline, it reads from a 
file.  Otherwise it writes data to a file. 
 
.PP 
When reading, one or more files must be specified.  Use 
\fB-\fP for stdin.  Input files that are 
compressed with \fBgzip\fR are supported 
automatically.  If the \fB\-l\fP option 
is specified then files are read from STDIN instead of  
the arguments. 
 
.PP 
When writing, a single output file must be specified with 
\fB\-w\fP. 
 
.PP 
The \fB\-s\fP option specifies the maximum file size (in 
megabytes) for output files.  If specified, the output file 
will have a two-digit suffix number appended and output will 
be split between as many files as necessary. 
 
.SS "cflowd Raw Flow File" 
.PP 
\fBcflow\fR \fIfilename\fR \&...  [-l ]  
.PP 
The \fBcflow\fR module reads from a raw flow file 
as created by cflowd.   
One or more files must be specified.  Use 
\fB-\fP for stdin.  Input files that are 
compressed with \fBgzip\fR are supported 
automatically.  If the \fB\-l\fP option 
is specified then files are read from STDIN instead of  
the arguments. 
 
.SS "Socket" 
.PP 
\fBsocket\fR [-p \fIport\fR]  [-h \fIhost\fR]  [-d]  
.PP 
The \fBsocket\fR module is used to send records 
across the network to another instantiation of the 
\fBsocket\fR module.  It can be used in two 
different ways: as a producer who receives data from the 
network, or as a consumer that writes data to a network.  If 
the module is at the beginning of a pipeline, it is assumed to 
be a server.  Otherwise it is a consumer that writes data to 
the network. 
 
.PP 
The \fB\-h\fP and \fB\-p\fP options 
specify a host and port, respectively.  The host option is required 
for a consumer.  The default port is 3000. 
 
.PP 
The \fB\-d\fP option is only valid in the server context. 
If specified, the module will continue to accept new 
connections forever and will never exit.  Without this option, 
the server will accept a single connection, process it until 
it closes, and then terminate. 
 
.SH "BOOLEAN FUNCTIONS" 
.SS "" 
.PP 
Boolean functions immediately either filter-out or pass-on each 
data object they are given. 
 
.SS "IP Address Mask Lookup" 
.PP 
\fBiplookup\fR\fIfield\fR  
.PP 
The "addr/cidr" argument is a CIDR netmask.  
An object is filtered out if 
and only if the specified field does not exist or does not 
match the given netmask. 
 
.PP 
Unlike the mask module, this module uses an efficient Patricia Trie 
to efficiently lookups in large vectors of masks. 
 
.SS "IP Address Mask" 
.PP 
\fBmask\fR\fIfield\fR [!]\fIaddr/cidr\fR  
.PP 
The "addr/cidr" argument is a CIDR netmask.  If the mask size 
is not specified, 32 is assumed.  An object is filtered out if 
and only if the specified field does not exist or does not 
match the given netmask.  If the address begins with a '!', 
then the logic is reversed and the object is filtered out if 
the field does match the netmask.   
 
.PP 
See also the iplookup module. 
 
.SS "Substring" 
.PP 
\fBsubstr\fR [\fIfield\fR] \fIstring\fR  [ ; \fIstring\fR \&...]  
.PP 
Search for each byte string in the specified field, or in the 
whole data object if no field is given.  If multiple strings 
are given, then each string corresponds to an output channel, 
and the object will be output only on the channel(s) that 
match. 
 
.SS "Filter" 
.PP 
\fBfilter\fR \fIfield [[<=>] value] ...\fR \&...  
.PP 
Filter out all objects in the stream that do not satisfy all 
of the specified criteria.  Expressions can be arbitrarily complex and include AND and OR  
statements and parentheses for grouping. 
 
.PP 
This is the select (sigma) 
operation from relational algebra ("where" in SQL). 
 
.SS "Unique Filter" 
.PP 
\fBuniq\fR [-m \fImegabytes\fR]  \fIfields\fR \&...  
.PP 
Treat the specified field(s) as a tuple and filter out all 
occurrences of duplicate values of that tuple. 
 
.PP 
The \fB\-m\fP option specifies that a probabilistic 
algorithm using a fixed amount of memory (specified in 
megabytes) should be employed.  Some records may be mistakenly 
filtered, but some large datasets cannot be processed with a 
perfect algorithm. 
 
.SS "Top" 
.PP 
\fBtop\fR [-m \fImegabytes\fR]  [-r \fIdeviation\fR]  \fIfields\fR \&...  
.PP 
Treat the specified field(s) as a tuple and count the number 
of occurrences of each values of that tuple.  Filter out all 
records except those whose occurrence deviates from the 
average by more than a factor of 
\fBdeviation\fR.  If no 
\fB\-r\fP option is specified, the default 
deviation threshold is 1. 
 
.PP 
If \fB\-m\fP is specified, then probabilistic 
counters are used, consuming a max of 
\fBmegabytes\fR memory, at the expense of 
some records not being filtered even though they're value is 
rare. 
 
.PP 
It is often useful to follow this module with 
\fBuniq\fR in order to get exact counts for all 
records that pass this filter. 
 
.SS "Head" 
.PP 
\fBhead\fR \fInumber\fR  
.PP 
Pass the first \fBnumber\fR records through 
and then end the pipeline.  Those records will be processed by 
all subsequent modules in the pipeline and the program will 
then terminate. 
 
.SH "ANNOTATION FUNCTIONS" 
.SS "" 
.PP 
An annotation function always adds a field to every data object and 
the name of that field is identical to the name of the function. 
 
.SS "Clock" 
.PP 
\fBclock\fR [ -t \fIseconds\fR]  \fIfield\fR  
.PP 
The clock module is used to bin input data into discrete 
clock periods.  Each object is annotated with a clock field 
containing the numerical value of the current clock.  The current  
clock value is determined by keeping track of the largest value 
seen for the specified field (presumably a time) and dividing 
that value by the optional time period, which defaults to 1.  
The input is assumed to be sorted in increasing order. 
 
.SS "Constant Annotation" 
.PP 
\fBconst\fR \fIstring\fR  [\fIfield\fR]  
.PP 
Annotate each object with a field containing the specified string constant. 
If a field name is specified, it will be used.  Otherwise, the name will be "const". 
 
.SS "Delta" 
.PP 
\fBdelta\fR \fIxfield\fR  
.PP 
For each data object seen, compute the delta from the previous x field to this current xfield. 
The data object is annotate with a "\fBdelta\fP" 
field of type "\fBdouble\fP" containing the result.  The x field must be convertable to doubles as well. 
 
.SS "Derivative" 
.PP 
\fBderivative\fR \fIyfield\fR \fIxfield\fR  
.PP 
For each data object seen, compute the derivative of the y field with respect to the x field 
between this point and the last object seen.  The data object is annotate with a "\fBderivative\fP" 
field of type "\fBdouble\fP" containing the result.  The x and y fields must be convertable 
to doubles as well. 
 
.SS "Flow ID" 
.PP 
\fBflowid\fR [-t \fItime\fR]  [-r ]  \fIfields\fR \&...  
.PP 
Treat the specified field(s) as a tuple and assign a unique 
flow id number to each object based on the typle value.  The 
annotated field is called "flowid".  All but the first packet 
will be filtered out. 
 
.PP 
The \fB\-r\fP option specifies that the same flow id 
should be assigned to packets in the reverse direction. 
Separate flow statistics will be kept for each direction. 
 
.PP 
The \fB\-t\fP option specifies a number of seconds 
idle time before a flow is timed out.  When it times out a 
REFRESH record with the flows identifying fields (as specified 
in the arguments), the current time (timeseries) and the 
packet and byte counters ("packets", "packetsback", "bytes", 
"bytesout") and the "start" and "finish" times. 
 
.SH "MISCELLANEOUS ANALYSIS FUNCTIONS" 
.SS "Counter" 
.PP 
\fBcount\fR [-a]  [-f \fIcountname\fR]  [-p]  [\fIfields\fR \&...]  
.PP 
If no fields are specified, simply count the number of records 
seen.  If one or more fields are specified, treat those fields 
as a tuple and count the number of occurrences of each value 
for that tuple.   
 
.PP 
Unless the "-p" flag is specified, then a double value named 
"probability" is annotated instead.  The "-f" flag can still 
be used to specify an alternate field name. 
 
.PP 
Normally an annotation is made to only the final object and all 
other objects are filtered out.  However, if the "-a" flag is given,  
then every object is passed and annotated with a 
running value. 
 
.SS "Stateful Matching" 
.PP 
\fBdfa\fR \fIstatefile\fR  
.PP 
The DFA module takes a input file describing 
transitions in a state machine.  Each line contains 
a current state, a subsequent state, and a 
predicate for the transition between those states. 
The predicate is in normal SMACQ syntax for a 
"where" clause.  States named START and STOP are 
required.  All other states can be named with any 
non-whitespace word. 
 
.PP 
The DFA module will create multiple instantiations of the 
given state machine.  However, a given input object is used by 
at most 1 of those instantiations.  When the DFA module 
receives an input object, any existing state machines are 
checked for possible transitions that would be satisfied by 
the object.  If none of the transitions from the current state 
of that machine are matched, then that machine will remain in 
the current state.  After a machine does match and transition 
on an input, no other machines will receive that input.  If no 
existing machines can use the input, then transitions from the 
START state are checked.  If the START state can be left, then 
a new machine is created. 
 
.SS "Last" 
.PP 
\fBlast\fR [-t \fItime\fR]  [\fIfields\fR \&...]  
.PP 
If any fields are specified, treat those fields as a tuple and keep track of the last object seen  
with that tuple value.  After there is no more data, output the objet for each tuple value. 
 
.PP 
The \fB\-t\fP option specifies, as a real number, 
the number of seconds between periodic updates.  After the specified 
amount of time, the last object seen for each tuple value will be emitted  
(just as is done at the end of the data stream).  At the end of the update, an 
object of type "\fBrefresh\fP" will be sent with a  
"\fBtimeseries\fP" field of type "\fBtimeval\fP" 
containing the time. 
Note: Time is not the wall-clock time, but is instead the 
time stored in the record in the 
"\fBtimeseries\fP" field of type 
"\fBtimeval\fP".  The \fB\-t\fP cannot 
be used with records that do not have this field. 
 
.SS "Discrete Probability Density Function" 
.PP 
\fBpdf\fR 
.PP 
Assemble a stream of input records with "count" fields. 
When a "refresh" record is received or the data flow ends, then  
use the "count" fields to calculate the fraction of the total  
that each record is responsible.  Attach this value as a "probability" 
field of type "double". 
calculate then use the  
 
.SS "Project" 
.PP 
\fBproject\fR \fIfields\fR \&...  
.PP 
Replace all objects in the input stream with new objects 
containing only the specified fields.  This is the project (Pi) 
operation from relational algebra ("select <fields>" in SQL). 
 
.SS "Rename" 
.PP 
\fBrename\fR \fIoldfield newfield\fR \&...  
.PP 
Given a list of alternating old and new field names, make a copy of the old field with the new name. 
Combined with the Project module, this can implement the rename (rho) 
operation from relational algebra ("as" in SQL). 
 
.SS "Entropy" 
.PP 
\fBentropy\fR 
.PP 
This module expects a series of data objects with "\fBprobability\fP" fields 
and computes the Shannon entropy for that series.   
When the data stream ends or a "\fBrefresh\fP" object is seen, it is assumed 
that every ocurring value has been seen and the entropy for the series is calculated 
and added as an annotation of type \fBdouble\fP to a refresh object.   
See the "\fBlast\fP" module for more information on \fBrefresh\fP objects. 
 
.SS "Group-By" 
.PP 
\fBgroupby\fR \fIfields\fR \&...  --   \fIquery\fR \&...  
.PP 
Treat the specified field(s) as a tuple and instantiate the 
specified query for each tuple.  If a record of type "refresh" 
is received, then the pipeline for that tuple will be gracefully 
terminated. 
 
.SS "Time Sort" 
.PP 
\fBfifodelay\fR [-t \fItime\fR]  [-i \fIinput-time-field\fR]  [-o \fIoutput-time-field\fR]  
.PP 
Sort a series of input records and output them sorted by an 
output time field that is specified with the 
\fB\-o\fP option and defaults to "timeseries".  All records 
that are past the edge time are immediately updated.  The edge 
time is determined by the input time field (specified with the 
\fB\-i\fP option and defaullting to "timseries") and 
a time delay which is specified with the \fB\-t\fP 	option which defaults to 0 seconds. 
 
.SH "QUERY SYNTAX" 
.PP 
SMACQ queries are specified using the following SQL-like grammer: 
 
.PP 
.nf 
.ta 8n 16n 24n 32n 40n 48n 56n 64n 72n 
query:  
action from [alias, joins] [WHERE boolean] [GROUP BY args [HAVING boolean]] 
| action [WHERE boolean] 
| WHERE boolean 
| query '|' action [WHERE boolean] [GROUP BY args [HAVING boolean]] 
 
action:  
function args 
| function ( args ) 
| ( query ) 
| ( parenquery + parenquery ) 
 
joins:  
[parenquery] alias [, joins] 
 
parenquery:  
( query ) 
| function ( args ) 
| function 
 
from:  
FROM action [from] 
 
 
.fi 
.PP 
Arguments can be given in a space separated list or a comma separated list. 
Any argument can be followed by the phrase "AS alias" to be 
given the specified alias. 
 
.PP 
.nf 
.ta 8n 16n 24n 32n 40n 48n 56n 64n 72n 
argument:  
word  
| function ( args )  
| '[' expression ']' 
 
boolean: 
( boolean ) 
| boolean AND boolean 
| boolean OR boolean 
| NOT boolean 
| operand 
| subexpression op subexpression 
| function ( args ) 
 
.fi 
.SH "SEE ALSO" 
.PP 
\fBsmacqq\fR(1),  
\fBDTS\fR(3),  
\fBSmacqGraph\fR(3) 
 
.\" created by instant / docbook-to-man, Sun 12 Dec 2004, 16:40 
