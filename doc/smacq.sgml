<!doctype refentry PUBLIC "-//OASIS//DTD DocBook V4.1//EN" [
  <!ENTITY docbook "<productname>DocBook</productname>">
  <!ENTITY sgml    "<abbrev>SGML</abbrev>">
]>

<refentry>
  <refentryinfo>
    <address>
      <email>mfisk@lanl.gov</email>
    </address>
    <author>
      <firstname>Mike</firstname>
      <surname>Fisk</surname>
    </author>
    <date>$Date: 2008/07/25 21:10:43 $</date>
  </refentryinfo>
  <refmeta>
    <refentrytitle>smacq</refentrytitle>
    <manvolnum>1</manvolnum>
  </refmeta>
  <refnamediv>
    <refname>smacq</refname>
    <refpurpose>System for Modular Analysis and Continuous Queries</refpurpose>
  </refnamediv>

  <refsect1>
    <title>DESCRIPTION</title>

      <para>
      The System for Modular Analysis and Continuous Queries (SMACQ)
      is an extensible component system for analyzing streams of
      structured data.  Users with a familiarity of SQL will
      immediately be comfortable using the basic features of the
      system.  However, there are additional object-relational and
      extensibility features that are described below.  This manpage
      describes the query syntax and the modules included with the
      system by default, which are grouped into sections for I/O,
      Boolean, Annotation, and Miscellaneous Analysis functions.
      Queries are executed using SMACQ's command-line utility,
      <command>smacqq(1)</command>, or the SMACQ C++ API.

      The primary difference from standard relational databases is
      that data is not stored in preloaded tables, but is instead
      produced by data source modules.  Also, the select operation
      does not automatically print fields.  If printable output is
      desired, use the <command>print</command> command.

      The following example prints the "srcip" and "dstip" fields from
      a stream of packets stored in a tcpdump-format file named "/tmp/dump":

      <computeroutput>
	print srcip, dstip from pcapfile("/tmp/dump")
      </computeroutput>

      Nested queries are also supported.  For example:

      <computeroutput>
	print srcip, dstip from (uniq srcip, dstip from pcapfile("/tmp/dump"))
      </computeroutput>

      When queries are nested deeply, the syntax described above can become
      complex.  As a result, commas are optional between arguments, and SMACQ 
      also supports the | symbol used in Unix shells.  The result is a syntax 
      much more familiar to Unix shell users.  Thus the following queries are 
      equivalent:

      <computeroutput>
	print srcip, dstip from (uniq srcip, dstip from pcapfile("/tmp/dump"))
      </computeroutput>

      <computeroutput>
	pcapfile "/tmp/dump" | uniq srcip dstip | print srcip dstip
      </computeroutput>

      "Where" clauses are supported for both boolean tests based on <,
      <=, >, >=, =, !=, or arbitrary filtering functions.

      <computeroutput>
	print dstip from pcapfile("/tmp/dump") where srcip = 128.129.1.2
      </computeroutput>

      <computeroutput>
	pcapfile /tmp/dump | where srcip = 128.129.1.2 | print dstip 
      </computeroutput>

      <computeroutput>
	print dstip from pcapfile("/tmp/dump") where mask(srcip, 128.129.0.0/16)
      </computeroutput>

      <computeroutput>
	pcapfile /tmp/dump | mask srcip 128.129.0.0/16 | print dstip 
      </computeroutput>

      Aliasing with "as" is supported:
      <computeroutput>
	print -v dstip, sum(len) as totalbytes from pcapfile("/tmp/dump"))
      </computeroutput>

      <computeroutput>
	pcapfile /tmp/dump | print -v dstip sum(len) as totalbytes
      </computeroutput>

    	Joins are supported as well:

	<computeroutput>
	print a.srcip, b.srcip from pcapfile("/tmp/dump") a, b where a.srcip != b.srcip	
	</computeroutput>

	When used with streams, joins require very large amounts of memory.  The "until" 
	term can be used to define when elements can be removed from the pool of possible
	values in a join:

	<computeroutput>
	print a.srcip, b.srcip from pcapfile("/tmp/dump") a until (new.a.ts > a.ts), b where a.srcip != b.srcip	
	</computeroutput>

      Extended relational algebra provides aggregate functions and the
      "group by" and "having" terms.  This syntax is supported, but with slightly
      different semantics.  For example, the following query would
      behave as it would in SQL:

      <computeroutput>
	print dstip, sum(len) from pcapfile("/tmp/dump") group by dstip
      </computeroutput>

      <computeroutput>
	pcapfile /tmp/dump | print dstip sum(len) group by dstip
      </computeroutput>

      but is also the same as:

      <computeroutput>
	pcapfile /tmp/dump | sum len group by dstip | print dstip sum
      </computeroutput>

      However the use of a function (such as "sum()") as one of the
      arguments will result in the "sum" module processing the data
      before the "print" module.  A module called in this way is
      expected to annotate the data object with a field of the same
      name as the function.  Thus, the sum field will be part of the
      object from now on.  Thus, it can also be used in subsequent
      arguments.  In addition, however, the module can cause other
      side-effects to the data.  Finally, functions can be used whether or
      not "group by" is used.


      SMACQ is an extensible system that the user can add modules to.
      See the <command>smacqp</command>(1) manpage for a detailed
      description of modules.  Many modules take flags which, like all
      arguments, can be separated with commas or spaces:

      <computeroutput>
	print -v, srcip, dstip from pcapfile("/tmp/dump")
      </computeroutput>&nbsp;
      </para>
  </refsect1>

  <refsect1>
    <title>INPUT/OUTPUT FUNCTIONS</title>

    <refsect2>
      <title>Print</title>
      <cmdsynopsis>
	<command>print</command>
	<arg choice="opt">-x</arg>
	<arg choice="opt">-v</arg>
	<arg choice="opt">-B</arg>
	<arg choice="opt">-d <replaceable>delimiter</replaceable></arg>
	<arg choice="opt" rep="repeat">fields</arg>
      </cmdsynopsis>

      <para>
	Print the specified fields for every record that has them If
	the <option>-v</option> option is given, then warnings are
	printed when fields aren't present, and field values are
	preceded by the field name.  If <option>-x</option> option
	is given, fields are surrounded with XML-style tags. 
	If the <option>-B</option> option
	is specified, then output is not buffered (output is flushed
	after each record).  Fields are separated by a delimiter
	string which can be specified by <option>-d</option> and
	defaults to TAB.  If no fields are specified, then all fields
	are printed.
      </para>
    </refsect2>

    <refsect2>
      <title>Tabular Input</title>
      <cmdsynopsis>
	<command>tabularinput</command>
	<arg choice="opt">-d <replaceable>delimiter</replaceable></arg>
	<arg choice="opt">-f <replaceable>filename</replaceable></arg>
	<arg choice="opt" rep="repeat">field<arg choice="opt">:type</arg></arg>
      </cmdsynopsis>

      <para>
	Read records from STDIN by default, or a filename specified with
	the <option>-f</option> option, one per line, with fields delimited
	by TAB or an alterate delimiter specified by
	<option>-d</option>.  If field names are specified, data
	columns are assigned those names sequentially.  If no field
	names are specified, or there are more columns that field
	names, unnamed fields are named numericaly starting at 1. 
      </para>

      <para>
	Field types can be specified by appending a colon and the type name to the end of the field name.
	If no type is sepecified for a field, it is treated as a double if possible, or a string otherwise.
      </para>
    </refsect2>

    <refsect2>
      <title>Packet Capture</title>
      <cmdsynopsis>
	<command>pcaplive</command>
	<arg>-i <replaceable>interface</replaceable></arg>
	<arg>-s <replaceable>snaplen</replaceable></arg>
	<arg>-p</arg>
	<arg rep="repeat"><replaceable>filter</replaceable></arg>
      </cmdsynopsis>

      <para>
	The <command>pcaplive</command> module reads packets from a
	network interfaces using libpcap.  It can only be used at the
	beginning of a pipeline.  Root privileges are typically
	required to run this module.
      </para>

      <para>
	The <option>-i</option> option specifies an interface to
	listen on (default is <literal>any</literal>).  The
	<option>-s</option> option specifies the maximum number of
	bytes per packet to capture (default is 68).  The
	<option>-p</option> specifies that the interface should NOT be
	placed in promiscuous mode.
      </para>

      <para>
	An optional filter string is a BPF filter string (see
	<command>tcpdump</command>(1)).
      </para>
    </refsect2>

    <refsect2>
      <title>Packet Capture File</title>
      <cmdsynopsis>
	<command>pcapfile</command>
	<arg choice="req" rep="repeat"> <replaceable>filename</replaceable></arg>
      </cmdsynopsis>
      <cmdsynopsis>
	<command>pcapfile</command>
	<arg choice="req"> -w <replaceable>filename</replaceable></arg>
	<arg>-l </arg>
	<arg>-s <replaceable>megabytes</replaceable></arg>
      </cmdsynopsis>

      <para>
	The <command>pcapfile</command> module either reads from or
	writes to a tcpdump-style, libpcap packet trace file.  If the
	module is at the beginning of a pipeline, it reads from a
	file.  Otherwise it writes data to a file.
      </para>

      <para>
	When reading, one or more files must be specified.  Use
	<literal>-</literal> for stdin.  Input files that are
	compressed with <command>gzip</command> are supported
	automatically.  If the <option>-l</option> option
	is specified then files are read from STDIN instead of 
	the arguments.
      </para>

      <para>
	When writing, a single output file must be specified with
	<option>-w</option>.
      </para>

      <para>
	The <option>-s</option> option specifies the maximum file size (in
	megabytes) for output files.  If specified, the output file
	will have a two-digit suffix number appended and output will
	be split between as many files as necessary.
      </para>
    </refsect2>

    <refsect2>
      <title>cflowd Raw Flow File</title>
      <cmdsynopsis>
	<command>cflow</command>
	<arg choice="req" rep="repeat"> <replaceable>filename</replaceable></arg>
	<arg>-l </arg>
      </cmdsynopsis>

      <para>
	The <command>cflow</command> module reads from a raw flow file
	as created by cflowd.  
	One or more files must be specified.  Use
	<literal>-</literal> for stdin.  Input files that are
	compressed with <command>gzip</command> are supported
	automatically.  If the <option>-l</option> option
	is specified then files are read from STDIN instead of 
	the arguments.
      </para>
    </refsect2>

    <refsect2>
      <title>Socket</title>
      <cmdsynopsis>
	<command>socket</command>
	<arg>-p <replaceable>port</replaceable></arg>
	<arg>-h <replaceable>host</replaceable></arg>
	<arg>-d</arg>
      </cmdsynopsis>

      <para>
	The <command>socket</command> module is used to send records
	across the network to another instantiation of the
	<command>socket</command> module.  It can be used in two
	different ways: as a producer who receives data from the
	network, or as a consumer that writes data to a network.  If
	the module is at the beginning of a pipeline, it is assumed to
	be a server.  Otherwise it is a consumer that writes data to
	the network.
      </para>

      <para>
	The <option>-h</option> and <option>-p</option> options
	specify a host and port, respectively.  The host option is required
	for a consumer.  The default port is 3000.
      </para>

      <para>
	The <option>-d</option> option is only valid in the server context.
	If specified, the module will continue to accept new
	connections forever and will never exit.  Without this option,
	the server will accept a single connection, process it until
	it closes, and then terminate.
      </para>
    </refsect2>

  </refsect1>
  <refsect1>
    <title>BOOLEAN FUNCTIONS</title>

    <refsect2>
      <title></title>
      <para>
      Boolean functions immediately either filter-out or pass-on each
      data object they are given.
      </para>
    </refsect2>

    <refsect2>
      <title>IP Address Mask Lookup</title>
      <cmdsynopsis>
	<command>iplookup</command>
	<arg choice="req"><replaceable>field</replaceable></arg>
      </cmdsynopsis>

      <para>
	The "addr/cidr" argument is a CIDR netmask. 
	An object is filtered out if
	and only if the specified field does not exist or does not
	match the given netmask.
      </para>
      <para>
        Unlike the mask module, this module uses an efficient Patricia Trie
	to efficiently lookups in large vectors of masks.
      </para>
    </refsect2>

    <refsect2>
      <title>IP Address Mask</title>
      <cmdsynopsis>
	<command>mask</command>
	<arg choice="req"><replaceable>field</replaceable></arg>
	<arg choice="req">[!]<replaceable>addr/cidr</replaceable></arg>
      </cmdsynopsis>

      <para>
	The "addr/cidr" argument is a CIDR netmask.  If the mask size
	is not specified, 32 is assumed.  An object is filtered out if
	and only if the specified field does not exist or does not
	match the given netmask.  If the address begins with a '!',
	then the logic is reversed and the object is filtered out if
	the field does match the netmask.  
      </para>
      <para>
        See also the iplookup module.
      </para>
    </refsect2>


    <refsect2>
      <title>Substring</title>
      <cmdsynopsis>
	<command>substr</command>
	<arg><replaceable>field</replaceable></arg>
	<arg choice="req"><replaceable>string</replaceable></arg>
	<arg rep="repeat"> ; <replaceable>string</replaceable></arg>
      </cmdsynopsis>

      <para>
        Search for each byte string in the specified field, or in the
        whole data object if no field is given.  If multiple strings
        are given, then each string corresponds to an output channel,
        and the object will be output only on the channel(s) that
        match.
      </para>
    </refsect2>

    <refsect2>
      <title>Filter</title>
      <cmdsynopsis>
	<command>filter</command>
	<arg choice="req" rep="repeat"> <replaceable>boolean-expression</replaceable></arg>
      </cmdsynopsis>

      <para>
        Do not specify this module; it is used internally for evaluating boolean expressions that do not have more optimal implementations.  Use a "where" clause in your query instead; "where" will instantiate a "filter" module only if necessary.
      </para>
	
    </refsect2>

    <refsect2>
      <title>Unique Filter</title>
      <cmdsynopsis>
	<command>uniq</command>
	<arg>-m <replaceable>megabytes</replaceable></arg>
	<arg choice="req" rep="repeat"> <replaceable>fields</replaceable></arg>
      </cmdsynopsis>

      <para>
	Treat the specified field(s) as a tuple and filter out all
	occurrences of duplicate values of that tuple.
      </para>

      <para>
	The <option>-m</option> option specifies that a probabilistic
	algorithm using a fixed amount of memory (specified in
	megabytes) should be employed.  Some records may be mistakenly
	filtered, but some large datasets cannot be processed with a
	perfect algorithm.
      </para>
      
    </refsect2>

    <refsect2>
      <title>Top</title>
      <cmdsynopsis>
	<command>top</command>
	<arg>-m <replaceable>megabytes</replaceable></arg>
	<arg>-r <replaceable>deviation</replaceable></arg>
	<arg choice="req" rep="repeat"> <replaceable>fields</replaceable></arg>
      </cmdsynopsis>

      <para>
	Treat the specified field(s) as a tuple and count the number
	of occurrences of each values of that tuple.  Filter out all
	records except those whose occurrence deviates from the
	average by more than a factor of
	<parameter>deviation</parameter>.  If no
	<option>-r</option> option is specified, the default
	deviation threshold is 1.
      </para>

      <para>
	If <option>-m</option> is specified, then probabilistic
	counters are used, consuming a max of
	<parameter>megabytes</parameter> memory, at the expense of
	some records not being filtered even though they're value is
	rare.
      </para>

      <para>
	It is often useful to follow this module with
	<command>uniq</command> in order to get exact counts for all
	records that pass this filter.
      </para>
    </refsect2>

    <refsect2>
      <title>Head</title>
      <cmdsynopsis>
	<command>head</command>
	<arg choice="req"> <replaceable>number</replaceable></arg>
      </cmdsynopsis>

      <para>
	Pass the first <parameter>number</parameter> records through
	and then end the pipeline.  Those records will be processed by
	all subsequent modules in the pipeline and the program will
	then terminate.
      </para>
    </refsect2>
  </refsect1>

  <refsect1>
    <title>ANNOTATION FUNCTIONS</title>
  
    <refsect2>
    <title></title>
    <para>
    An annotation function always adds a field to every data object and
    the name of that field is identical to the name of the function.
    </para>
    </refsect2>

    <refsect2>
      <title>Clock</title>
      <cmdsynopsis>
	<command>clock</command> 
	<arg> -t <replaceable>seconds</replaceable></arg>
	<arg choice="req"> <replaceable>field</replaceable></arg>
      </cmdsynopsis>

      <para>
	The clock module is used to bin input data into discrete
	clock periods.  Each object is annotated with a clock field
	containing the numerical value of the current clock.  The current 
	clock value is determined by keeping track of the largest value
	seen for the specified field (presumably a time) and dividing
	that value by the optional time period, which defaults to 1. 
	The input is assumed to be sorted in increasing order.
      </para>
    </refsect2>

    <refsect2>
      <title>Constant Annotation</title>
      <cmdsynopsis>
	<command>const</command> 
	<arg choice="opt">-t <replaceable>type</replaceable></arg>
	<arg choice="opt">-f <replaceable>field</replaceable></arg>
	<arg choice="req"> <replaceable>string</replaceable></arg>
	<arg><replaceable>field</replaceable></arg>
      </cmdsynopsis>

      <para>
	Annotate each object with a field containing the specified constant.  The default field name is "const" and the default type is "string".
      </para>
    </refsect2>
    <refsect2>
      <title>Delta</title>
      <cmdsynopsis>
	<command>delta</command>
	<arg choice="req"> <replaceable>xfield</replaceable></arg>
      </cmdsynopsis>

      <para>
	For each data object seen, compute the delta from the previous x field to this current xfield.
	The data object is annotate with a "<literal>delta</literal>"
	field of type "<literal>double</literal>" containing the result.  The x field must be convertable to doubles as well.
      </para>
    </refsect2>

    <refsect2>
      <title>Derivative</title>
      <cmdsynopsis>
	<command>derivative</command>
	<arg choice="req"> <replaceable>yfield</replaceable></arg>
	<arg choice="req"><replaceable>xfield</replaceable></arg>
      </cmdsynopsis>

      <para>
	For each data object seen, compute the derivative of the y field with respect to the x field
	between this point and the last object seen.  The data object is annotate with a "<literal>derivative</literal>"
	field of type "<literal>double</literal>" containing the result.  The x and y fields must be convertable
	to doubles as well.
      </para>
    </refsect2>

    <refsect2>
      <title>Div</title>
      <cmdsynopsis>
	<command>div</command> 
	<arg> -d <replaceable>divisor</replaceable></arg>
	<arg><replaceable>field</replaceable></arg>
      </cmdsynopsis>

      <para>
	The div module annotates each object with a field of type
	"int" and the name "div".  The field is computed by dividing
	the speficied field by the specified divisor (or 1 by
	default).  The result is then truncated.  See the "clock"
	module for similar functionality.
      </para>
    </refsect2>

    <refsect2>
      <title>Flow ID</title>
      <cmdsynopsis>
	<command>flowid</command>
	<arg>-t <replaceable>time</replaceable></arg>
	<arg>-r </arg>
	<arg choice="req" rep="repeat"> <replaceable>fields</replaceable></arg>
      </cmdsynopsis>

      <para>
	Treat the specified field(s) as a tuple and assign a unique
	flow id number to each object based on the typle value.  The
	annotated field is called "flowid".  All but the first packet
	will be filtered out.
      </para>

      <para>
	The <option>-r</option> option specifies that the same flow id
	should be assigned to packets in the reverse direction.
	Separate flow statistics will be kept for each direction.
      </para>

      <para>
	The <option>-t</option> option specifies a number of seconds
	idle time before a flow is timed out.  When it times out a
	REFRESH record with the flows identifying fields (as specified
	in the arguments), the current time (timeseries) and the
	packet and byte counters ("packets", "packetsback", "bytes",
	"bytesout") and the "start" and "finish" times.
      </para>
    </refsect2>
      
    <refsect2>
      <title>Now</title>
      <cmdsynopsis>
	<command>now</command> 
	<arg> -f <replaceable>field</replaceable></arg>
      </cmdsynopsis>

      <para>
	The now module annotates each object with an object of type
	"timeval" (a struct timeval) with the given name, or "now" by
	default.
      </para>
    </refsect2>

  </refsect1>
    
  <refsect1>
    <title>MISCELLANEOUS ANALYSIS FUNCTIONS</title>
    <refsect2>
      <title>Counter</title>
      <cmdsynopsis>
	<command>count</command>
	<arg>-a</arg>
	<arg>-f <replaceable>countname</replaceable></arg>
	<arg>-p</arg>
	<arg rep="repeat"><replaceable>fields</replaceable></arg>
      </cmdsynopsis>

      <para>
	If no fields are specified, simply count the number of records
	seen.  If one or more fields are specified, treat those fields
	as a tuple and count the number of occurrences of each value
	for that tuple.  
      </para>
   
      <para>
	Unless the "-p" flag is specified, then a double value named
	"probability" is annotated instead.  The "-f" flag can still
	be used to specify an alternate field name.
      </para>

      <para>
        Normally an annotation is made to only the final object and all
	other objects are filtered out.  However, if the "-a" flag is given, 
	then every object is passed and annotated with a
	running value.
      </para>
    </refsect2>

    <refsect2>
      <title>Deskew</title>
      <cmdsynopsis>
	<command>deskew</command>
	<arg>-s <replaceable>secondaryfield<replaceable></arg>
	<arg>-b <replaceable>min<replaceable></arg>
	<arg>-e <replaceable>max<replaceable></arg>
	<arg rep="repeat"><replaceable>fields</replaceable></arg>
      </cmdsynopsis>

      <para>
	The deskew module is designed to take a stream of in-order timeseries data where some of the time values are incorrect and outside a range of possible values.  The range is specified with "-b" and "-e".  Any such illegal values are replaced with the previous valid value in the stream.  This operation is performed on the specified field.  If a second field is specified with "-s", then that field is adjusted by an equal amount.
      </para>
    </refsect2>

    <refsect2>
      <title>Sort</title>
      <cmdsynopsis>
	<command>sort</command>
	<arg>-r</arg>
	<arg>-b <replaceable>batchsize</replaceable></arg>
	<arg rep="repeat"><replaceable>fields</replaceable></arg>
      </cmdsynopsis>

      <para>
	Buffer-up the input datastream and output a sorted stream.  If "-b" is not specified, 
	no data will be output until the input stream closes.  If "-b n" is specified, then sorted
	data will be output after every n records.
      </para>

      <para>
	Any fields that are specified that have "double" fields, will be sorted numerically.  All
	other fields will be sorted byte by byte in their native storage format.
      </para>
   
      <para>
        The -r option specifies descending order instead of the default, ascending order.
      </para>
    </refsect2>

    <refsect2>
      <title>Take</title>
      <cmdsynopsis>
	<command>take</command>
	<arg><replaceable>field</replaceable></arg>
      </cmdsynopsis>

      <para>
	This module outputs the object specified field of every input object.  For example, if an input
	stream consists of objects with a "timestamp" field (and any number of other fields), and "timestamp"
	is the specified field name for take, then the output stream will consist of those timestamp fields.
      </para>

      <para>
	This is similar to the "project" function, and the project operator in relational algebra (select in SQL), except that a single
	object is returned rather than a tuple of values.
    </refsect2>

    <refsect2>
      <title>Stateful Matching</title>
      <cmdsynopsis>
	<command>dfa</command>
	<arg choice="req"> <replaceable>statefile</replaceable></arg>
	
      </cmdsynopsis>

      <para>
                   The DFA module takes a input file describing
                   transitions in a state machine.  Each line contains
                   a current state, a subsequent state, and a
                   predicate for the transition between those states.
                   The predicate is in normal SMACQ syntax for a
                   "where" clause.  States named START and STOP are
                   required.  All other states can be named with any
                   non-whitespace word.
      </para>
      <para>
	The DFA module will create multiple instantiations of the
	given state machine.  However, a given input object is used by
	at most 1 of those instantiations.  When the DFA module
	receives an input object, any existing state machines are
	checked for possible transitions that would be satisfied by
	the object.  If none of the transitions from the current state
	of that machine are matched, then that machine will remain in
	the current state.  After a machine does match and transition
	on an input, no other machines will receive that input.  If no
	existing machines can use the input, then transitions from the
	START state are checked.  If the START state can be left, then
	a new machine is created.
      </para>
    </refsect2>

    <refsect2>
      <title>Last</title>
      <cmdsynopsis>
	<command>last</command>
	<arg>-t <replaceable>time</replaceable></arg>
	<arg rep="repeat"><replaceable>fields</replaceable></arg>
      </cmdsynopsis>

      <para>
        If any fields are specified, treat those fields as a tuple and keep track of the last object seen 
	with that tuple value.  After there is no more data, output the objet for each tuple value.
      </para>

      <para>
	The <option>-t</option> option specifies, as a real number,
	the number of seconds between periodic updates.  After the specified
        amount of time, the last object seen for each tuple value will be emitted 
	(just as is done at the end of the data stream).  At the end of the update, an
        object of type "<literal>refresh</literal>" will be sent with a 
	"<literal>timeseries</literal>" field of type "<literal>timeval</literal>"
	containing the time.
	Note: Time is not the wall-clock time, but is instead the
	time stored in the record in the
	"<literal>timeseries</literal>" field of type
	"<literal>timeval</literal>".  The <option>-t</option> cannot
	be used with records that do not have this field.
      </para>
      
    </refsect2>

    <refsect2>
      <title>Discrete Probability Density Function</title>
      <cmdsynopsis>
	<command>pdf</command>
      </cmdsynopsis>

      <para>
        Assemble a stream of input records with "count" fields.
	When a "refresh" record is received or the data flow ends, then 
	use the "count" fields to calculate the fraction of the total 
	that each record is responsible.  Attach this value as a "probability"
	field of type "double".
	calculate then use the 
      </para>
    </refsect2>

    <refsect2>
      <title>Private Field Namespace</title>
      <cmdsynopsis>
	<command>private</command>
      </cmdsynopsis>

      <para>
        Return a new object that shares the same data, but has its own namespace for
		fields.  The namespace is initially the same as the original, but new fields 
		that are added are private to the new copy.
	  </para>
    </refsect2>

    <refsect2>
      <title>Project</title>
      <cmdsynopsis>
	<command>project</command>
	<arg choice="req" rep="repeat"> <replaceable>fields</replaceable></arg>
      </cmdsynopsis>

      <para>
        Replace all objects in the input stream with new objects
        containing only the specified fields.  This is the project (Pi)
        operation from relational algebra ("select &lt;fields&gt;" in SQL).
      </para>
    </refsect2>

    <refsect2>
      <title>Rename</title>
      <cmdsynopsis>
	<command>rename</command>
	<arg choice="req" rep="repeat"> <replaceable>oldfield newfield</replaceable></arg>
      </cmdsynopsis>

      <para>
        Given a list of alternating old and new field names, make a copy of the old field with the new name.
        Combined with the Project module, this can implement the rename (rho)
        operation from relational algebra ("as" in SQL).
      </para>
    </refsect2>

    <refsect2>
      <title>Entropy</title>
      <cmdsynopsis>
	<command>entropy</command>
      </cmdsynopsis>

      <para>
        This module expects a series of data objects with "<literal>probability</literal>" fields
	and computes the Shannon entropy for that series.  
	When the data stream ends or a "<literal>refresh</literal>" object is seen, it is assumed
	that every ocurring value has been seen and the entropy for the series is calculated
	and added as an annotation of type <literal>double</literal> to a refresh object.  
	See the "<literal>last</literal>" module for more information on <literal>refresh</literal> objects.
      </para>
    </refsect2>

    <refsect2>
      <title>Time Sort</title>
      <cmdsynopsis>
	<command>fifodelay</command>
	<arg>-t <replaceable>time</replaceable></arg>
	<arg>-i <replaceable>input-time-field</replaceable></arg>
	<arg>-o <replaceable>output-time-field</replaceable></arg>
      </cmdsynopsis>

      <para>
	Sort a series of input records and output them sorted by an
	output time field that is specified with the
	<option>-o</option> option and defaults to "timeseries".  All records
	that are past the edge time are immediately updated.  The edge
	time is determined by the input time field (specified with the
	<option>-i</option> option and defaullting to "timseries") and
	a time delay which is specified with the <option>-t</option>
	option which defaults to 0 seconds.
      </para>
    </refsect2>

  </refsect1>


  <refsect1>
    <title>QUERY SYNTAX</title>
    <para>
    SMACQ queries are specified using the following SQL-like grammer:
    </para>

    <literallayout>
    query: 
		action from [alias, joins] [WHERE boolean] [GROUP BY args [HAVING boolean]]
		| action [WHERE boolean]
		| WHERE boolean
		| query '|' action [WHERE boolean] [GROUP BY args [HAVING boolean]]

	action: 
		function args
		| function ( args )
		| ( query )
		| ( parenquery + parenquery )

    joins: 
		[parenquery] alias [, joins]
	   
    parenquery: 
		( query )
		| function ( args )
		| function

    from: 
		FROM action [from]

    </literallayout>

    <para>
    Arguments can be given in a space separated list or a comma separated list.
    Any argument can be followed by the phrase "AS alias" to be
    given the specified alias.
    </para>

    <literallayout>
    argument: 
		word 
		| function ( args ) 
		| '[' expression ']'

    boolean:
		( boolean )
		| boolean AND boolean
		| boolean OR boolean
		| NOT boolean
		| operand
		| subexpression op subexpression
		| function ( args )
    </literallayout>

  </refsect1>

  <refsect1>
    <title>SEE ALSO</title>

    <para>
      <command>smacqq</command>(1), 
      <command>DTS</command>(3), 
      <command>SmacqGraph</command>(3)
    </para>

  </refsect1>
  
</refentry>
